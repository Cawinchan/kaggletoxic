{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "DATA_FILE = './data/train.csv'\n",
    "W2V_MODEL = './models/w2v.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "\n",
    "def load_w2v_model_from_path(model_path, binary_input=False):\n",
    "    \"\"\"\n",
    "    :param model_path: path to w2v model\n",
    "    :type model_path: string\n",
    "    :param binary_input: True : binary input, False : text input\n",
    "    :type binary_input: boolean\n",
    "    :return: loaded w2v model\n",
    "    :rtype: KeyedVectors object\n",
    "    \"\"\"\n",
    "    w2v_model = KeyedVectors.load_word2vec_format(model_path, binary=binary_input)\n",
    "    return w2v_model\n",
    "\n",
    "\n",
    "model = load_w2v_model_from_path(W2V_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "full_data_set = []\n",
    "\n",
    "with open(DATA_FILE) as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for line in reader:\n",
    "        full_data_set.append(line)\n",
    "\n",
    "# load data into native lists\n",
    "print(header)\n",
    "id_data = [i for i in map(lambda x: x[0], full_data_set)]\n",
    "text_data = [i for i in map(lambda x: x[1], full_data_set)]\n",
    "toxic_data = [i for i in map(lambda x: x[2], full_data_set)]\n",
    "severe_toxic_data = [i for i in map(lambda x: x[3], full_data_set)]\n",
    "obscene_data = [i for i in map(lambda x: x[4], full_data_set)]\n",
    "threat_data = [i for i in map(lambda x: x[5], full_data_set)]\n",
    "insult_data = [i for i in map(lambda x: x[6], full_data_set)]\n",
    "identity_hate_data = [i for i in map(lambda x: x[6], full_data_set)]\n",
    "full_data = {'id' : id_data,'toxic' :toxic_data,'severe_toxic' : severe_toxic_data,'obscene' : obscene_data ,'threat' : threat_data,'insult' : insult_data,'identity_hate' : identity_hate_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "max_length = 0\n",
    "#tokenize sentences\n",
    "tokenized_sentences = []\n",
    "for sentence in text:\n",
    "    tokenized_sentences.append(tknzr.tokenize(sentence))\n",
    "    max_length = max(max_length,len(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/edwin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "#keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32',\n",
    "#    padding='pre', truncating='pre', value=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorise sentences\n",
    "removed_indexes = []\n",
    "vectorized_sentences = []\n",
    "for i in range(len(tokenized_sentences)):\n",
    "    tokenized_sentence = tokenized_sentences[i]\n",
    "    if len(tokenized_sentence) > 50 :\n",
    "        tokenized_sentence = tokenized_sentence[:50]\n",
    "    vector_rep_of_sentence = []\n",
    "    for word in tokenized_sentence:\n",
    "        if word in model.vocab:\n",
    "            vector_rep_of_sentence.append(model.wv[word])\n",
    "    if not vector_rep_of_sentence :\n",
    "        removed_indexes.append(i)\n",
    "    else :\n",
    "        array = np.array(vector_rep_of_sentence)\n",
    "        zeroes = np.zeros((50-len(vector_rep_of_sentence),300))\n",
    "        vector_rep_of_sentence = np.concatenate((array,zeroes),axis=0)\n",
    "        vectorized_sentences.append(vector_rep_of_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorized_sentences_np = np.array(vectorized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_remove_indexes_from_list(list_of_indexes,full_data_set):\n",
    "    list_of_indexes.sort(reverse=True) #always remove the largest indexes first or you will get an index error\n",
    "    for key in full_data_set : #for each sequence\n",
    "        sequence = full_data_set[key]\n",
    "        for index in list_of_indexes : #iterate through index\n",
    "            sequence.pop(index)\n",
    "        full_data_set[key] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_remove_indexes_from_list(removed_indexes,full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in full_data :\n",
    "    assert len(full_data[key]) == len(vectorized_sentences_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorized_sentences_np [-10000:]\n",
    "x_test = vectorized_sentences_np [:10000]\n",
    "y_train = full_data['toxic'] [-10000:]\n",
    "y_test = full_data['toxic'] [:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.2166 - acc: 0.9260 - val_loss: 0.1896 - val_acc: 0.9426\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1467 - acc: 0.9503 - val_loss: 0.1382 - val_acc: 0.9516\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1313 - acc: 0.9575 - val_loss: 0.1390 - val_acc: 0.9465\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1174 - acc: 0.9594 - val_loss: 0.1254 - val_acc: 0.9559\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1111 - acc: 0.9621 - val_loss: 0.1352 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f727e58a780>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 300\n",
    "timesteps = 50\n",
    "num_classes = 2\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_predict = model.predict(x_train[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted is 0.008796238340437412, truth is 0,\n",
      "predicted is 0.002557283965870738, truth is 0,\n",
      "predicted is 0.0020868261344730854, truth is 0,\n",
      "predicted is 0.9687802195549011, truth is 1,\n",
      "predicted is 0.0025312425568699837, truth is 0,\n",
      "predicted is 0.968778133392334, truth is 1,\n",
      "predicted is 0.0023737496230751276, truth is 0,\n",
      "predicted is 0.0023098685778677464, truth is 0,\n",
      "predicted is 0.003657362423837185, truth is 0,\n",
      "predicted is 0.002309787319973111, truth is 0,\n",
      "predicted is 0.003101394744589925, truth is 0,\n",
      "predicted is 0.05995829775929451, truth is 0,\n",
      "predicted is 0.0022372365929186344, truth is 0,\n",
      "predicted is 0.002550855278968811, truth is 0,\n",
      "predicted is 0.0402420312166214, truth is 0,\n",
      "predicted is 0.9661478996276855, truth is 1,\n",
      "predicted is 0.01763775385916233, truth is 0,\n",
      "predicted is 0.24867761135101318, truth is 0,\n",
      "predicted is 0.9689835906028748, truth is 1,\n",
      "predicted is 0.00342194945551455, truth is 0,\n",
      "predicted is 0.007008715067058802, truth is 0,\n",
      "predicted is 0.0030895350500941277, truth is 0,\n",
      "predicted is 0.00374640803784132, truth is 0,\n",
      "predicted is 0.014107841067016125, truth is 1,\n",
      "predicted is 0.04354718327522278, truth is 0,\n",
      "predicted is 0.0024741077795624733, truth is 0,\n",
      "predicted is 0.0027338850777596235, truth is 0,\n",
      "predicted is 0.7747523188591003, truth is 1,\n",
      "predicted is 0.0025230690371245146, truth is 0,\n",
      "predicted is 0.0023134658113121986, truth is 0,\n",
      "predicted is 0.0025525556411594152, truth is 0,\n",
      "predicted is 0.0028926064260303974, truth is 0,\n",
      "predicted is 0.015558729879558086, truth is 0,\n",
      "predicted is 0.002496986882761121, truth is 0,\n",
      "predicted is 0.008393908850848675, truth is 0,\n",
      "predicted is 0.002503457246348262, truth is 0,\n",
      "predicted is 0.003216805635020137, truth is 0,\n",
      "predicted is 0.0035090481396764517, truth is 0,\n",
      "predicted is 0.00318191503174603, truth is 0,\n",
      "predicted is 0.0029592476785182953, truth is 0,\n",
      "predicted is 0.0025068027898669243, truth is 0,\n",
      "predicted is 0.0022708543110638857, truth is 0,\n",
      "predicted is 0.9281995296478271, truth is 1,\n",
      "predicted is 0.0024905316531658173, truth is 0,\n",
      "predicted is 0.0021683552768081427, truth is 0,\n",
      "predicted is 0.8313841819763184, truth is 1,\n",
      "predicted is 0.002243256662040949, truth is 0,\n",
      "predicted is 0.0021941722370684147, truth is 0,\n",
      "predicted is 0.0035468637943267822, truth is 0,\n",
      "predicted is 0.813520073890686, truth is 1,\n",
      "predicted is 0.005258035846054554, truth is 0,\n",
      "predicted is 0.0021724561229348183, truth is 0,\n",
      "predicted is 0.20853640139102936, truth is 0,\n",
      "predicted is 0.025720996782183647, truth is 0,\n",
      "predicted is 0.002331006107851863, truth is 0,\n",
      "predicted is 0.6056625843048096, truth is 1,\n",
      "predicted is 0.012866648845374584, truth is 0,\n",
      "predicted is 0.004624026361852884, truth is 0,\n",
      "predicted is 0.00254651065915823, truth is 0,\n",
      "predicted is 0.9545774459838867, truth is 0,\n",
      "predicted is 0.0023608598858118057, truth is 0,\n",
      "predicted is 0.010414612479507923, truth is 0,\n",
      "predicted is 0.004117194097489119, truth is 0,\n",
      "predicted is 0.0026081956457346678, truth is 0,\n",
      "predicted is 0.8675628304481506, truth is 1,\n",
      "predicted is 0.0023771566338837147, truth is 0,\n",
      "predicted is 0.007608000189065933, truth is 0,\n",
      "predicted is 0.0023237518034875393, truth is 0,\n",
      "predicted is 0.0027585639618337154, truth is 0,\n",
      "predicted is 0.0026408941484987736, truth is 0,\n",
      "predicted is 0.9416252374649048, truth is 1,\n",
      "predicted is 0.0023887872230261564, truth is 0,\n",
      "predicted is 0.00237592332996428, truth is 0,\n",
      "predicted is 0.5668392181396484, truth is 0,\n",
      "predicted is 0.028530873358249664, truth is 0,\n",
      "predicted is 0.002250589895993471, truth is 0,\n",
      "predicted is 0.0034919390454888344, truth is 0,\n",
      "predicted is 0.0034301122650504112, truth is 0,\n",
      "predicted is 0.49773189425468445, truth is 0,\n",
      "predicted is 0.9686887264251709, truth is 1,\n",
      "predicted is 0.00226242165081203, truth is 0,\n",
      "predicted is 0.002453393302857876, truth is 0,\n",
      "predicted is 0.007875245995819569, truth is 0,\n",
      "predicted is 0.00229241861961782, truth is 0,\n",
      "predicted is 0.043646834790706635, truth is 0,\n",
      "predicted is 0.00289798597805202, truth is 0,\n",
      "predicted is 0.002603456610813737, truth is 0,\n",
      "predicted is 0.03114882856607437, truth is 0,\n",
      "predicted is 0.7584155201911926, truth is 1,\n",
      "predicted is 0.003005167469382286, truth is 0,\n",
      "predicted is 0.003407774493098259, truth is 0,\n",
      "predicted is 0.002367980545386672, truth is 0,\n",
      "predicted is 0.002667888067662716, truth is 0,\n",
      "predicted is 0.0024961826857179403, truth is 0,\n",
      "predicted is 0.0023786122910678387, truth is 0,\n",
      "predicted is 0.002500950824469328, truth is 0,\n",
      "predicted is 0.0032414202578365803, truth is 0,\n",
      "predicted is 0.0024968297220766544, truth is 0,\n",
      "predicted is 0.0993286520242691, truth is 0,\n",
      "predicted is 0.005637060850858688, truth is 0,\n"
     ]
    }
   ],
   "source": [
    "for index,val in enumerate(x_predict) :\n",
    "    print(\"predicted is {}, truth is {},\".format(x_predict[index][0],y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
